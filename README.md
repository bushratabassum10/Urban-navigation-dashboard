<p align="center">
  <img width="1888" height="874" alt="image" src="https://github.com/user-attachments/assets/91cc6d85-1332-4049-af15-c9ffe6274fb7" />
</p>



# Urban-Navigation-Dashboard


A live dashboard for real-time urban navigation, combining YOLOv11-driven perception with live weather feeds to support adaptive routing and safer mobility.


## Authors  

**Bushra Tabassum**  
Researcher in Biomedical Signal Processing, AI in Healthcare, and Digital Twin  
[GitHub Profile](https://github.com/bushratabassum10)
---
**Md. Irteeja Kobir (Irteeja)**  
Enthusiast in Machine Learning, Deep Learning & Natural Language Processing  
[GitHub Profile](https://github.com/Irteeja)  
---
## Overview

This dashboard demonstrates how perception and weather data can be fused to aid safer, more resilient urban traversal. It uses:

- **YOLOv11** for detecting urban elements like vehicles, pedestrians, and cyclists.
- **Live weather feeds** to adjust routing dynamically based on conditions.
- **Real-time rerouting** that either penalises or blocks problematic road segments.
- A clean, user-friendly **HTML/CSS/JavaScript interface** for visual monitoring.

---

## Features

- Real-time object detection with adaptive responses to environmental changes.
- Dynamic route adjustment prioritising safety under adverse weather.
- Web-based display with room for expansion â€” ideal for research or demos.

---

## Getting Started

To run locally:

```bash
git clone https://github.com/bushratabassum10/urban-navigation-dashboard.git
cd urban-navigation-dashboard
python -m http.server 8000
Bushra Tabassum *Urban-Navigation-Dashboard*, GitHub repository, 2025.  
Available: https://github.com/bushratabassum10/urban-navigation-dashboard
